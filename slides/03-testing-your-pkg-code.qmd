---
title: "Ensuring your code works as expected - and introduction to testing"
format: 
  revealjs:
    slide-number: true
    slide-level: 4
editor: source
---

## Testability

Testability is defined as the degree to which a system 
or component facilitates the establishment of test objectives 
and the execution of tests to determine 
whether those objectives have been achieved.

In order to be successful, 
a test needs to be able to execute the code you wish to test, 
in a way that can trigger a defect 
that will propagate an incorrect result to a program point
where it can be checked against the expected behaviour. 

## High-level properties for effective test writing and execution

**controllability**: the code under test needs to be able to be programmatically controlled

**observability**: the outcome of the code under test needs to be able to be verified

**isolateablilty**: the code under test needs to be able to be validated on its own

**automatability**: the tests should be able to be executed automatically

Source: [CPSC 310](https://github.com/ubccpsc/310/blob/master/resources/readings/TestabilityAssertions.md) 
& [CPSC 410](https://www.cs.ubc.ca/~rtholmes/teaching/2015t1/cpsc410/slides/410_19_testability.pdf) class notes from Reid Holmes, UBC]

## What kinds of tests do we write for our functions?

When I am designing tests for my function, 
I like to think about three broad categories of tests, 
and then write 2-3 tests for each 
(or more if the function is complex and takes many arguments):

- Simple expected use cases

- Edge cases (unexpected, or rare use cases)

- Errors

We will come back to these and provide specific examples in a few minutes.

## When do we write tests? 

Anytime you think about writing a function!

## Workflow for writing functions and tests

1. Write the function specifications and documentation - 
but do not implement the function.

2. Plan the test cases and document them.

3. Create test data that is useful for assessing whether your function works as expected.

4. Write the tests to evaluate your function based on the planned test cases and test data.

5. Implement the function by writing the needed code in the function body to pass the tests.

6. Iterate between steps 2-5 to improve the test coverage and function.

## Example of workflow for writing functions and tests for data science

Let's pretend we haven't yet written our `count_classes` function, 
and follow the workflow I just outlined to develop our function 
and it's test suite.

### 1. Write the function specifications and documentation - but do not implement the function

The first thing we should do is write the function specifications and documentation. This can effectively represented by an empty function and roxygen2-styled documentation in R as shown below:

```{r}
#| eval: false

#' Count class observations
#'
#' Creates a new data frame with two columns, 
#' listing the classes present in the input data frame,
#' and the number of observations for each class.
#'
#' @param data_frame A data frame or data frame extension (e.g. a tibble).
#' @param class_col unquoted column name of column containing class labels
#'
#' @return A data frame with two columns. 
#'   The first column (named class) lists the classes from the input data frame.
#'   The second column (named count) lists the number of observations for each class from the input data frame.
#'   It will have one row for each class present in input data frame.
#'
#' @export
#'
#' @examples
#' count_classes(mtcars, am)
count_classes <- function(data_frame, class_col) {
  # returns a data frame with two columns: class and count
}
```

### 2. Plan the test cases and document them

Next, we should plan out our test cases and start to document them. 

At this point we can sketch out a skeleton for our test cases with code 
but we are not yet ready to write them, 
as we first will need to reproducibly create test data 
that is useful for assessing whether your function works as expected. 

### 2. Plan the test cases and document them (cont'd)

So considering our function specifications, 
some kinds of input we might anticipate our function may receive, 
and correspondingly what it should return is listed in a table below:

TBD...

### 2. Plan the test cases and document them (cont'd)

Next, I sketch out a skeleton for the unit tests. 
For R, we will use the well maintained 
and popular [`testthat`](https://testthat.r-lib.org/) R package 
for writing our tests. 

With `testthat` we create a `test_that` statement 
for each related group of tests for a function. 
For our example, we will create the four `test_that` statements shown below:

```{r}
#| eval: false

test_that("`count_classes` should return a data frame or data frame extension", {
  # tests to be added here
})

test_that("`count_classes` should return a data frame, or data frame extension, 
with the number of rows that corresponds to the number of unique classes 
in the column passed to `class_col`", {
  # tests to be added here
})

test_that("`count_classes` should return a data frame, or data frame extension, 
whose values in the `count` column correspond to the number of observations 
for the group in the `class` column from the original data frame", {
  # tests to be added here
})

test_that("`count_classes` should throw an error when incorrect types 
are passed to `data_frame` and `class_col` arguments", {
  # tests to be added here
})
```

### 3. Create test data that is useful for assessing whether your function works as expected

Now that we have a plan, we can create reproducible test data for that plan! When we do this, we want to keep our data as small and tractable as possible. We want to test things we know the answer to, or can at a minimum calculate by hand. We will use R code to reproducibly create the test data. We will need to do this for the data we will feed in as inputs to our function in the tests, as well as the data we expect our function to return.

```{r}
#| eval: false

# function input for tests
five_classes_3_obs <- data.frame(class_lables = rep(c("class1", "class2", "class3", "class4", "class5"), 3))
two_classes_3_obs <- data.frame(class_lables = rep(c("class1", "class2"), 3))
two_classes_3_and_2_obs <- data.frame(class_lables = c(rep(c("class1", "class2"), 2), "class1"))
two_classes_3_and_1_obs <- data.frame(class_lables = c(rep("class1", 3), "class2"))
one_class_3_obs <- data.frame(class_lables = rep("class1", 3))
empty_df  <- data.frame(class_lables = character(0))
vector_class_labels <- rep(c("class1", "class2"), 3)
two_classes_3_obs_as_list <- list(class_lables = rep(c("class1", "class2"), 3))

# expected function output
five_classes_3_obs_output <- data.frame(class = c("class1", "class2", "class3", "class4", "class5"),
                                        count = rep(3, 5))
two_classes_3_obs_output <- data.frame(class = c("class1", "class2"),
                                count = c(3, 3))
two_classes_3_and_2_obs_output <- data.frame(class = c("class1", "class2"),
                                      count = c(3, 2))
two_classes_3_and_1_obs_output <- data.frame(class = c("class1", "class2"),
                                      count = c(3, 1))
one_class_3_obs_output <- data.frame(class = "class1",
                              count = 3)
empty_df_output <- data.frame(class = character(0),
                              count = numeric(0))
```

### 4. Write the tests to evaluate your function based on the planned test cases and test data

Now that we have the skeletons for our tests, and our reproducible test data, we can actually write the internals for our tests! We will do this by using expect_* functions from the testthat package. The table below shows some of the most commonly used expect_* functions. However, there are many more that can be found in the testthat expectations reference documentation.

testthat test structure:

```{r}
#| eval: false

test_that("Message to print if test fails", expect_*(...))
```

### 4. Write the tests to evaluate your function based on the planned test cases and test data (cont'd)

#### Common expect_* statements for use with `test_that`:

Is the object equal to a value?

- `expect_identical` - test two objects for being exactly equal
- `expect_equal` - compare R objects x and y testing ‘near equality’ (can set a tolerance)
- `expect_equivalent` - compare R objects x and y testing ‘near equality’ (can set a tolerance) and does not assess attributes

Does code produce an output/message/warning/error?

- `expect_error` - tests if an expression throws an error
- `expect_warning` - tests whether an expression outputs a warning
- `expect_output` - tests that print output matches a specified value

Is the object true/false?

These are fall-back expectations that you can use when none of the other more specific expectations apply. The disadvantage is that you may get a less informative error message.

- `expect_true` - tests if the object returns TRUE
- `expect_false` - tests if the object returns FALSE

4. 

```{r}
#| eval: false

test_that("`count_classes` should return a tibble", {
  expect_s3_class(count_classes(two_classes_3_obs, class_lables), "tibble")
})

test_that("`count_classes` should return a data frame, or data frame extension, 
with the number of rows that corresponds to the number of unique classes 
in the column passed to `class_col`", {
  expect_equivalent(count_classes(five_classes_3_obs, class_lables), five_classes_3_obs_output)
  expect_equivalent(count_classes(two_classes_3_obs, class_lables), two_classes_3_obs_output)
  expect_equivalent(count_classes(one_class_3_obs, class_lables), one_class_3_obs_output)
  expect_equivalent(count_classes(empty_df, class_lables), empty_df_output)
})

test_that("`count_classes` should return a data frame, or data frame extension, 
whose values in the `count` column correspond to the number of observations 
for the group in the `class` column from the original data frame", {
  expect_equivalent(count_classes(two_classes_3_and_2_obs, class_lables), two_classes_3_and_2_obs_output)
  expect_equivalent(count_classes(two_classes_3_and_1_obs, class_lables), two_classes_3_and_1_obs_output)
})

test_that("`count_classes` should throw an error when incorrect types 
are passed to `data_frame` and `class_col` arguments", {
  expect_error(count_classes(two_classes_3_obs, vector_class_labels))
  expect_error(count_classes(two_classes_3_obs_as_list, class_lables))
})
```


### Wait what??? Most of our tests fail…

Yes, we expect that, we haven’t written our function body yet!

### 5. Implement the function by writing the needed code in the function body to pass the tests

FINALLY!! We can write the function body for our function! And then call our tests to see if they pass!

```{r}
#| eval: false

#' Count class observations
#'
#' Creates a new data frame with two columns, 
#' listing the classes present in the input data frame,
#' and the number of observations for each class.
#'
#' @param data_frame A data frame or data frame extension (e.g. a tibble).
#' @param class_col unquoted column name of column containing class labels
#'
#' @return A data frame with two columns. 
#'   The first column (named class) lists the classes from the input data frame.
#'   The second column (named count) lists the number of observations for each class from the input data frame.
#'   It will have one row for each class present in input data frame.
#'
#' @export
#'
#' @examples
#' count_classes(mtcars, am)
count_classes <- function(data_frame, class_col) {
    if (!is.data.frame(data_frame)) {
        stop("`data_frame` should be a data frame or data frame extension (e.g. a tibble)")
    }
    
    data_frame |>
        dplyr::group_by({{ class_col }}) |>
        dplyr::summarize(count = dplyr::n()) |>
        dplyr::rename("class" = {{ class_col }})
}
```

### 6. Iterate between steps 2-5 to improve the test coverage and function

Are we done? For the purposes of this demo, yes! However in practice you would usually cycle through steps 2-5 two-three more times to further improve our tests and and function

## Where do the function and test files go?

In the workflow above, 
we skipped over where we should put our tests 
and how to call them in an automated way.

Let's go to this version of the <span style="color: purple;">{eda}</span> package and explore how to do this:

- TBD
